@article{Fernandez-Quintanilla2018,
abstract = {Weed monitoring is the first step in any site-specific weed management programme. A relatively large variety of platforms, cameras, sensors and image analysis procedures are available to detect and map weed presence/abundance at various times and spatial scales. Remote sensing from satellites or aircraft can provide accurate weed maps when the images are obtained at late weed phenological stages. Cameras located on unmanned aerial vehicles (UAVs) have been shown to be adequate for early-season weed detection in a variety of wide-row crops, providing images with relatively high spatial resolutions. Alternatively, weed detection/mapping systems from ground-based platforms can achieve even higher resolutions using a variety of non-imaging and imaging technologies. These ground systems are suited, in some cases, for real-time site-specific weed management. Despite this rich arsenal of technologies, their commercial adoption is, apparently, low. In this study, we describe the state of the art of remotely sensed and ground-based weed monitoring in arable crops and the current level of adoption of these technologies, exploring major constraints for adoption and trying to identify research gaps and bottlenecks.},
author = {Fern{\'{a}}ndez-Quintanilla, C and Pe{\~{n}}a, J M and And{\'{u}}jar, D and Dorado, J and Ribeiro, A and L{\'{o}}pez-Granados, F},
doi = {10.1111/wre.12307},
editor = {Smith, Richard},
issn = {00431737},
journal = {Weed Research},
keywords = {cameras,ground-based platforms,image analysis,real-time detection,sensors,unmanned aerial vehicle,weed maps},
mendeley-groups = {AI,UAV,Review Paper,Image Processing,Weed Control},
month = {aug},
number = {4},
pages = {259--272},
publisher = {Blackwell Publishing Ltd},
title = {{Is the current state of the art of weed monitoring suitable for site-specific weed management in arable crops?}},
url = {http://doi.wiley.com/10.1111/wre.12307},
volume = {58},
year = {2018}
}
@article{Huang2016,
abstract = {Agricultural remote sensing has been developed and applied in monitoring soil, crop growth, weed infestation, insects, diseases and water status in farm fields to provide data and information to guide agricultural management practices. Precision agriculture has been implemented through prescription mapping of crop fields at different scales with the data remotely sensed from space-borne, airborne and ground-based platforms. Ground-based remote sensing techniques offer portability, flexibility and controllability in applications for precision agriculture. In weed management, crop injury from off-target herbicide spray drift and herbicide resistance in weeds are two important issues. For precision weed management, ground-based hyperspectral remote sensing techniques were developed for detection of crop injury from dicamba and differentiation between glyphosate resistant and sensitive weeds. This research presents the techniques for ground-based hyperspectral remote sensing for these two applications. Results illustrate the advantages of ground-based hyperspectral remote sensing for precision weed management.},
author = {Huang, Yanbo and Lee, Matthew A. and Thomson, Steven J. and Reddy, Krishna N.},
doi = {10.3965/j.ijabe.20160902.2137},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Huang et al. - 2016 - Ground-based hyperspectral remote sensing for weed management in crop production.pdf:pdf},
issn = {19346352},
journal = {International Journal of Agricultural and Biological Engineering},
keywords = {Crop injury,Ground-based remote sensing,Herbicide resistance,Hyperspectral,Precision agriculture},
mendeley-groups = {Just Intro Refs},
month = {mar},
number = {2},
pages = {98--109},
publisher = {Chinese Society of Agricultural Engineering},
title = {{Ground-based hyperspectral remote sensing for weed management in crop production}},
url = {http://www.ijabe.org},
volume = {9},
year = {2016}
}
@article{Barrero2018,
abstract = {In this paper, a new method to fuse low resolution multispectral and high resolution RGB images is introduced, in order to detect Gramineae weed in rice fields with plants at 50 days after emergence (DAE).The images are taken from a fixed-wing unmanned aerial vehicle (UAV) at 60 and 70 m altitude. The proposed method combines the texture information given by a high resolution red–green–blue (RGB) image and the reflectance information given by a low resolution multispectral (MS) image, to obtain a fused RGB-MS image with better weed discrimination features. After analyzing the normalized difference vegetation index (NDVI) and normalized green red difference index (NGRDI) for weed detection, it was found that NGRDI presents better features. The fusion method consists of decomposing the RGB image using the intensity, hue and saturation (IHS) transformation, then, a second order Haar wavelet transformation is applied to the intensity layer (I) and the NGRDI image. From this transformation, the low–low (LL) coefficients of the NGRDI image are replaced by the LL coefficients of the I layer. Finally, the fused image is obtained by transforming the new wavelet coefficients to RGB space. To test the method, a one hectare experimental plot with rice plants at 50 DAE with Gramineae weeds was selected. Additionally, to compare the performance of the method, two indices were used, specifically, the M/MGT index which is the percentage of detected weed area, and the MP index which indicates the precision of weed detection. These indices were evaluated in four validation zones using three Neural Networks (NN) detection systems based on three types of images; namely, RGB, RGB + NGRDI, and fused RGB-NGRDI. The best weed detection performance was obtained by the NN with the fused image, with M/MGT index between 80 and 108% and MP between 70 and 85%.},
author = {Barrero, Oscar and Perdomo, Sammy A.},
doi = {10.1007/s11119-017-9558-x},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Barrero, Perdomo - 2018 - RGB and multispectral UAV image fusion for Gramineae weed detection in rice fields.pdf:pdf},
issn = {15731618},
journal = {Precision Agriculture},
keywords = {Image fusion,Multispectral images,Neural Networks,UAVs,Vegetation index,Weed detection},
mendeley-groups = {Just Intro Refs},
month = {oct},
number = {5},
pages = {809--822},
publisher = {Springer New York LLC},
title = {{RGB and multispectral UAV image fusion for Gramineae weed detection in rice fields}},
volume = {19},
year = {2018}
}
@inproceedings{Sanders2019,
abstract = {Copyright {\textcopyright} 2019 SPIE. Advancements in efficient unmanned aerial platforms and affordable sensors has led to renewed interest in remote sensing by agricultural producers and land managers for use as an efficient and convenient method of evaluating crop status and pest issues in their fields. For remote sensing to be employed as a viable and widespread tool for weed management, the accurate detection of distinct weed species must be possible through the use of analytical procedures on the resultant imagery. Additionally, the remote sensing platform and subsequent analysis must be capable of identifying these species across a wide range of heights. In 2017, a field study was performed to identify any weed height thresholds on the accurate detection and subsequent classification of three common broadleaf weed species in the southeastern United States: Palmer amaranth (Amaranthus palmeri), common ragweed (Ambrosia artemisiifolia) and sicklepod Senna obtusifolia) as well as the classification accuracy of image classifications performed on the species scale. Pots of the three species at heights of 5, 10, 15, and 30 cm were randomly arranged in a grid and 5-band multispectral imagery was collected at 15 m. Image analysis was used to identify the spectral reflectance behavior of the weed species and height combinations and to evaluate the accuracy of species based supervised classifications involving the three species. Supervised classification was able to discriminate between the three weed species with between 24-100% accuracy depending on height and species. Palmer amaranth classification accuracy was consistently 100%. Increased height of sicklepod and common ragweed plants did not reliably confer improved accuracy but the species were correctly identified with at least 24% and 60% accuracy, respectively.},
author = {Sanders, John and Everman, Wesley J. and Austin, R. and Roberson, G. T. and Richardson, R. J.},
doi = {10.1117/12.2519306},
isbn = {9781510626799},
issn = {1996756X},
mendeley-groups = {Just Intro Refs},
month = {may},
pages = {24},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Weed species differentiation using spectral reflectance land image classification}},
year = {2019}
}
@article{Reddy2014,
abstract = {BACKGROUND: Palmer amaranth (Amaranthus palmeri S. Wats.) is a troublesome agronomic weed in the southern United States, and several populations have evolved resistance to glyphosate. This paper reports on spectral signatures of glyphosate-resistant (GR) and glyphosate-sensitive (GS) plants, and explores the potential of using hyperspectral sensors to distinguish GR from GS plants. RESULTS: GS plants have higher light reflectance in the visible region and lower light reflectance in the infrared region of the spectrum compared with GR plants. The normalized reflectance spectrum of the GR and GS plants had best separability in the 400-500 nm, 650-690 nm, 730-740 nm and 800-900 nm spectral regions. Fourteen wavebands from within or near these four spectral regions provided a classification of unknown set of GR and GS plants, with a validation accuracy of 94% for greenhouse-grown plants and 96% for field-grown plants. CONCLUSIONS: GR and GS Palmer amaranth plants have unique hyperspectral reflectance properties, and there are four distinct regions of the spectrum that can separate the GR from GS plants. These results demonstrate that hyperspectral imaging has potential application to distinguish GR from GS Palmer amaranth plants (without a glyphosate treatment), with future implications for glyphosate resistance management. Published 2014. This article is a U.S. Government work and is in the public domain in the USA.},
author = {Reddy, Krishna N and Huang, Yanbo and Lee, Matthew A and Nandula, Vijay K and Fletcher, Reginald S and Thomson, Steven J and Zhao, Feng},
doi = {10.1002/ps.3755},
issn = {1526498X},
journal = {Pest Management Science},
keywords = {Glyphosate-resistant weeds,Herbicide-resistant weeds,Hyperspectral imaging,Palmer amaranth,Weed classification},
mendeley-groups = {Just Intro Refs},
month = {dec},
number = {12},
pages = {1910--1917},
publisher = {John Wiley and Sons Ltd},
title = {{Glyphosate-resistant and glyphosate-susceptible Palmer amaranth ( <i>Amaranthus palmeri</i> S. Wats.): hyperspectral reflectance properties of plants and potential for classification}},
url = {http://doi.wiley.com/10.1002/ps.3755},
volume = {70},
year = {2014}
}
@article{wang2019review,
abstract = {Weeds are among the major factors that could harm crop yield. With the advances in electronic and information technologies, machine vision combined with image processing techniques has become a promising tool for precise real-time weed and crop detection in the field, providing valuable sensing information for site-specific weed management. This review summarized the advances of weed detection using ground-based machine vision and image processing techniques. Concretely, the four procedures, i.e., pre-processing, segmentation, feature extraction and classification, for weed detection were presented in detail. To separate vegetation from background, different color indices and classification approaches like color index-based, threshold-based and learning-based ones, were developed. The difficulty of weed detection lies in discriminating between crops and weeds that often have similar properties. Generally, four categories of features, i.e., biological morphology, spectral features, visual textures and spatial contexts, were used for the task, which were discussed in this review. Application of conventional machine learning-based and recently developed deep learning-based approaches for weed detection were also presented. Finally, challenges and solutions provided by researchers for weed detection in the field, including occlusion and overlap of leaves, varying lighting conditions and different growth stages, were discussed.},
author = {Wang, Aichen and Zhang, Wen and Wei, Xinhua},
doi = {10.1016/j.compag.2019.02.005},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Wang, Zhang, Wei - 2019 - A review on weed detection using ground-based machine vision and image processing techniques.pdf:pdf},
issn = {01681699},
journal = {Computers and electronics in agriculture},
keywords = {Image processing,Machine vision,Precision agriculture,Site-specific weed management,Weed detection},
mendeley-groups = {Image Processing,Weed Control,Precision Agriculture,Review Paper,AI},
month = {mar},
pages = {226--240},
publisher = {Elsevier},
title = {{A review on weed detection using ground-based machine vision and image processing techniques}},
volume = {158},
year = {2019}
}
@article{Li,
abstract = {Typically, herbicides are applied uniformly to the entire field rather than be applied to the critical areas where they're most needed. And existing weed identification approaches, such as manual visual scouting and ground-based proximal sensing, are labor intensive, time consuming, and do not scale easily to large areas. To facilitate more efficient farming, new technologies must be developed that can achieve optimal weed management and increase the crop yield by a magnitude. To date, rapid advances in UAV technology has enabled sufficient lifting capacity and endurance to support high resolution imagery over large areas. With the FAA planning to integrate UAVs into the national airspace (NAS), UAV-based aerial weed scouting is now possible to bring promising significant benefits for farmers. An unmanned aerial vehicle based aerial weed scout with machine vision system was proposed and developed for the weed identification with the sensing capability from far above the field to close to the canopy, and measuring the plant/weed density (weed infestation rate)/weed species. The canopy was segmented from the background by greenness selection and thresholding. The crop row and its centroid line was calculated and masked by its pixel density. The anomalous weed patches between the crop rows was identified and its population was mapped. For species identification, a machine learning approach is used. Convolutional Neural Network (CNN) as one of deep learning method has the advantage of less neuron weight, easy for training and good robust performance in displacement, scale and deformation, which is promising for the weed specifies classification and probability assessment. The previous weed distribution mapping and individual weed extraction helps to generate the training data and highlights their own features, which could ensure the weed identification classifier robustness and efficiency. The preliminary result shows the specific weed type could be classified probably. The results show that the proposed approach will provide an efficient and promising tool for farmers' weed identification and the resulting infestation mapping will enable a better weed control recommendation.},
author = {Li and Huang, Xiaoyun and Orlando, Florida},
doi = {10.13031/aim.20162462667},
keywords = {Aerial weed scout,Unmanned aerial vehicle(UAV),convention neural network(CNN),deep learning,image processing,machine vision},
mendeley-groups = {Image Classification,UAV,Weed Control,AI},
title = {{Real-time UAV weed scout for selective weed control by adaptive robust control and machine learning algorithm}},
url = {http://www.asabe.org/copyright}
}
@article{Young2018a,
abstract = {<p>Precision means being exact and accurate and is an important management component for cropping systems. However, precision does not mean integration, which encompasses spatial and temporal dimensions and is a necessary practice rivaling precision. True IWM merges precision and integration by incorporating advanced technology that allows for greater flexibility of inputs and enhanced responsiveness to field conditions. Examples of this approach are non-existent due to a lack of suitable technological tools and a need for a paradigm shift. Herein a potential model startup company is offered as a guide to advance beyond precision weed control to true integration. The critical components of such a company include grower connections, investor support, proven and reliable technology, and adaptability and innovation in the agricultural technology market. The company with the vision and incentive to make true IWM a reality will be the first to more fully integrate available tools using technology, thus helping many growers overcome ongoing challenges associated with resistance, soil erosion, drift, and weed seedbanks.</p>},
author = {Young, Stephen L.},
doi = {10.1017/wet.2017.70},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Young - 2018 - Beyond Precision Weed Control A Model for True Integration.pdf:pdf;:C\:/Users/Salazar/Documents/Mendeley Desktop/Young - 2018 - Beyond Precision Weed Control A Model for True Integration(2).pdf:pdf},
issn = {0890-037X},
journal = {Weed Technology},
keywords = {Advanced technology,UAV,automation,decision support,robotics,true IWM},
mendeley-groups = {Weed Control,Precision Agriculture},
month = {feb},
number = {1},
pages = {7--10},
publisher = {Cambridge University Press},
title = {{Beyond Precision Weed Control: A Model for True Integration}},
url = {https://www.cambridge.org/core/product/identifier/S0890037X17000707/type/journal_article},
volume = {32},
year = {2018}
}
@article{ranganathan2018sustainably,
author = {Ranganathan, Janet and Waite, Richard and Searchinger, Tim and December, Craig Hanson},
journal = {World Resources Institute},
mendeley-groups = {Misc},
number = {1},
pages = {1--14},
title = {{How to Sustainably Feed 10 Billion People by 2050 , in 21 Charts}},
url = {https://www.wri.org},
year = {2018}
}
@article{golijan2018global,
abstract = {A produ{\c{c}}{\~{a}}o agr{\'{i}}cola org{\^{a}}nica possibilita a produ{\c{c}}{\~{a}}o controlada, certificada,alimentos seguros e de alta qualidade e, ao mesmo tempo, proporciona alta economia elucro ecol{\'{o}}gico e preserva um ambiente saud{\'{a}}vel. Interesses do consumidor em produtos deA origem org{\^{a}}nica vem crescendo h{\'{a}} vinte anos. O objetivo deste artigo {\'{e}}dar uma vis{\~{a}}o geral da situa{\c{c}}{\~{a}}o no mercado global de alimentos org{\^{a}}nicos, bem como apontaros motivos mais importantes para os consumidores decidirem sobre o consumo dealimentos produzidos. Todos os pa{\'{i}}ses do mundo registram uma tend{\^{e}}ncia de alimentos org{\^{a}}nicos cont{\'{i}}nuose crescimento do mercado de bebidas. Em alguns pa{\'{i}}ses, esse crescimento {\'{e}} expresso com duplan{\'{u}}meros de d{\'{i}}gitos. Os Estados Unidos s{\~{a}}o o maior mercado de alimentos org{\^{a}}nicos, com um total de 35,8trilh{\~{a}}o de euros. Frutas, legumes, p{\~{a}}o, cereais, bebidas, leite e carne t{\^{e}}m as maioresparticipa{\c{c}}{\~{a}}o no mercado de alimentos org{\^{a}}nicos em todos os pa{\'{i}}ses do mundo. Frutas frescas s{\~{a}}o as primeirasposi{\c{c}}{\~{a}}o no com{\'{e}}rcio internacional. Embora a produ{\c{c}}{\~{a}}o e venda de alimentos org{\^{a}}nicos sejaconcentrados em pa{\'{i}}ses altamente desenvolvidos, pa{\'{i}}ses menos desenvolvidos est{\~{a}}o se tornandoimportantes produtores e exportadores de produtos org{\^{a}}nicos},
author = {Golijan, Jelena and Dimitrijevi{\'{c}}, Bojan},
doi = {10.5937/aaser1846125g},
issn = {0354-9542},
journal = {Acta agriculturae Serbica},
mendeley-groups = {Misc},
number = {46},
pages = {125--140},
title = {{Global organic food market}},
volume = {23},
year = {2018}
}
@online{GRV:2017,
author = {{Grand View Research}},
mendeley-groups = {Misc},
title = {{Organic Food And Beverages Market Size, Share \& Trends Analysis Report By Product (Organic Food, Organic Beverage), By Region, And Segment Forecasts, 2018 - 2025}},
url = {https://www.grandviewresearch.com/industry-analysis/organic-foods-beverages-market},
year = {2017}
}
@article{silva2018feeding,
author = {Silva, George},
journal = {Michigan State University Extension--3 December},
mendeley-groups = {Misc},
title = {{Feeding the World in 2050 and Beyond--Part 1: Productivity Challenges}},
year = {2018}
}
@article{timmermann2003economic,
author = {Timmermann, C and Gerhards, Roland and K{\"{u}}hbauch, W},
journal = {Precision Agriculture},
mendeley-groups = {Weed Control},
number = {3},
pages = {249--260},
publisher = {Springer},
title = {{The economic impact of site-specific weed control}},
volume = {4},
year = {2003}
}
@article{dyrmann2017roboweedsupport,
author = {Dyrmann, Mads and J{\o}rgensen, Rasmus Nyholm and Midtiby, Henrik Skov},
journal = {Adv. Anim. Biosci},
mendeley-groups = {Robotics,Weed Control},
number = {2},
pages = {842--847},
title = {{RoboWeedSupport-Detection of weed locations in leaf occluded cereal crops using a fully convolutional neural network}},
volume = {8},
year = {2017}
}
@article{johnsongiant,
author = {Johnson, Bill and Loux, Mark and Nordby, Dawn and Sprague, Christy and Nice, Glenn and Westhoven, Andy and Stachler, Jeff},
mendeley-groups = {Weed Control},
title = {{Giant Ragweed}}
}
@article{grichar2009effect,
author = {Grichar, W James and Prostko, Eric P},
journal = {Crop Protection},
mendeley-groups = {Weed Control},
number = {7},
pages = {619--622},
publisher = {Elsevier},
title = {{Effect of glyphosate and fungicide combinations on weed control in soybeans}},
volume = {28},
year = {2009}
}
@article{van2019management,
author = {{Van De Stroet}, Brian and Clay, Sharon A},
journal = {Agrosystems, Geosciences \& Environment},
mendeley-groups = {Misc},
number = {1},
pages = {1--9},
publisher = {Wiley Online Library},
title = {{Management Considerations for Palmer Amaranth in a Northern Great Plains Soybean Production System}},
volume = {2},
year = {2019}
}
@article{travlos2011corn,
author = {Travlos, Ilias S and Economou, Garifalia and Kanatas, Panagiotis J},
journal = {Agronomy Journal},
mendeley-groups = {Early Season Weed},
number = {1},
pages = {1--6},
publisher = {Wiley Online Library},
title = {{Corn and barnyardgrass competition as influenced by relative time of weed emergence and corn hybrid}},
volume = {103},
year = {2011}
}
@online{bayerGiantRag,
author = {{Bayer AG}},
mendeley-groups = {Weed Control},
title = {{How to Manage and Control Ragweed in Corn and Soybeans}},
url = {https://www.cropscience.bayer.us/learning-center/articles/dont-let-ragweed-wreak-havoc-on-yields}
}
@article{lopez2011weed,
author = {L{\'{O}}PEZ-GRANADOS, Francisca},
journal = {Weed Research},
mendeley-groups = {Image Processing,Weed Control,Precision Agriculture},
number = {1},
pages = {1--11},
publisher = {Wiley Online Library},
title = {{Weed detection for site-specific weed management: mapping and real-time approaches}},
volume = {51},
year = {2011}
}
@incollection{hussain2018mechanical,
author = {Hussain, Mubshar and Farooq, Shahid and Merfield, Charles and Jabran, Khawar},
booktitle = {Non-Chemical Weed Control},
mendeley-groups = {Weed Control},
pages = {133--155},
publisher = {Elsevier},
title = {{Mechanical weed control}},
year = {2018}
}
@article{van2016survey,
author = {{Van Wychen}, L},
journal = {Weed Science Society of America National Weed Survey Dataset. http://wssa. net/wp-content/uploads/2016\_Weed\_Survey\_Final. xlsx. Accessed: October},
mendeley-groups = {Misc},
pages = {2017},
title = {{Survey of the most common and troublesome weeds in broadleaf crops, fruits \& vegetables in the United States and Canada}},
volume = {5},
year = {2016}
}
@book{legleiter2013palmer,
author = {Legleiter, Travis R and Johnson, Bill},
mendeley-groups = {Misc},
publisher = {Purdue Extension West Lafayette, IN},
title = {{Palmer amaranth biology, identification, and management}},
year = {2013}
}
@article{tona2018profitability,
author = {Tona, Emanuele and Calcante, Aldo and Oberti, Roberto},
journal = {Precision Agriculture},
mendeley-groups = {Precision Agriculture},
number = {4},
pages = {606--629},
publisher = {Springer},
title = {{The profitability of precision spraying on specialty crops: a technical--economic analysis of protection equipment at increasing technological levels}},
volume = {19},
year = {2018}
}
@article{ahmad2018visual,
author = {Ahmad, Jamil and Muhammad, Khan and Ahmad, Imran and Ahmad, Wakeel and Smith, Melvyn L and Smith, Lyndon N and Jain, Deepak Kumar and Wang, Haoxiang and Mehmood, Irfan},
journal = {Computers in Industry},
mendeley-groups = {AI,Image Processing,Image Classification,Weed Control,Precision Agriculture},
pages = {23--33},
publisher = {Elsevier},
title = {{Visual features based boosted classification of weeds for real-time selective herbicide sprayer systems}},
volume = {98},
year = {2018}
}
@misc{GrandViewMarket2017,
author = {{Grand View Market}},
mendeley-groups = {Misc},
title = {{Organic Food And Beverages Market | Global Industry Report, 2025}},
url = {https://www.grandviewresearch.com/industry-analysis/organic-foods-beverages-market},
urldate = {2021-02-21},
year = {2017}
}
@article{Jha2019,
abstract = {Agriculture automation is the main concern and emerging subject for every country. The world population is in- creasing at a very fast rate and with increase in population the need for food increases briskly. Traditional methods used by farmers aren't sufficient enough to serve the increasing demand and so they have to hamper the soil by using harmful pesticides in an intensified manner. This affects the agricultural practice a lot and in the end the land remains barren with no fertility. This paper talks about different automation practices like IOT, Wireless Communications, Machine learning and Artificial Intelligence, Deep learning. There are some areas which are causing the problems to agriculture field like crop diseases, lack of storage management, pesti- cide control, weed management, lack of irrigation and water management and all this problems can be solved by above mentioned different techniques. Today, there is an urgent need to decipher the issues like use ofharm- ful pesticides, controlled irrigation, control on pollution and effects ofenvironment in agricultural practice. Auto- mation of farming practices has proved to increase the gain from the soil and also has strengthened the soil fertility. This paper surveys the work ofmany researchers to get a briefoverview about the current implementa- tion ofautomation in agriculture. The paper also discusses a proposed systemwhich can be implemented in bo- tanical farm for flower and leaf identification and watering using IOT.},
author = {Jha, Kirtan and Doshi, Aalap and Patel, Poojan and Shah, Manan},
doi = {10.1016/j.aiia.2019.05.004},
issn = {25897217},
journal = {Artificial Intelligence in Agriculture},
mendeley-groups = {Review Paper,AI},
month = {jun},
pages = {1--12},
publisher = {Elsevier BV},
title = {{A comprehensive review on automation in agriculture using artificial intelligence}},
volume = {2},
year = {2019}
}
@article{Soltani2016,
abstract = {<p> Crop losses from weed interference have a significant effect on net returns for producers. Herein, potential corn yield loss because of weed interference across the primary corn-producing regions of the United States and Canada are documented. Yield-loss estimates were determined from comparative, quantitative observations of corn yields between nontreated and treatments providing greater than 95% weed control in studies conducted from 2007 to 2013. Researchers from each state and province provided data from replicated, small-plot studies from at least 3 and up to 10 individual comparisons per year, which were then averaged within a year, and then averaged over the seven years. The resulting percent yield-loss values were used to determine potential total corn yield loss in t ha <sup>−1</sup> and bu acre <sup>−1</sup> based on average corn yield for each state or province, as well as corn commodity price for each year as summarized by USDA-NASS (2014) and Statistics Canada (2015). Averaged across the seven years, weed interference in corn in the United States and Canada caused an average of 50% yield loss, which equates to a loss of 148 million tonnes of corn valued at over U.S.$26.7 billion annually. </p>},
author = {Soltani, Nader and Dille, J. Anita and Burke, Ian C. and Everman, Wesley J. and VanGessel, Mark J. and Davis, Vince M. and Sikkema, Peter H.},
doi = {10.1614/WT-D-16-00046.1},
issn = {0890-037X},
journal = {Weed Technology},
keywords = {Best Management Practices,Canada,USA,crop losses,economic loss,herbicides,weed management,weeds},
mendeley-groups = {Weed Control,Misc},
month = {dec},
number = {4},
pages = {979--984},
publisher = {Cambridge University Press (CUP)},
title = {{Potential Corn Yield Losses from Weeds in North America}},
url = {https://www.cambridge.org/core/product/identifier/S0890037X00022831/type/journal_article},
volume = {30},
year = {2016}
}
@article{Soltani,
author = {Soltani, N and Dille, JA and Burke, IC and {\ldots}, WJ Everman - Weed and undefined 2017},
journal = {cambridge.org},
mendeley-groups = {Weed Control,Misc},
title = {{Perspectives on potential soybean yield losses from weeds in North America}},
url = {https://www.cambridge.org/core/journals/weed-technology/article/perspectives-on-potential-soybean-yield-losses-from-weeds-in-north-america/839B31C6771865071E6956BAEFC0F076}
}
@article{Hunter2020,
abstract = {In recent years, unmanned aerial vehicle (UAV) technology has expanded to include UAV sprayers capable of applying pesticides. Very little research has been conducted to optimize application parameters and measure the potential of off-target movement from UAV-based pesticide applications. Field experiments were conducted in Raleigh, NC during spring 2018 to characterize the effect of different application speeds and nozzle types on target area coverage and uniformity of UAV applications. The highest coverage was achieved with an application speed of 1 m s-1 and ranged from 30% to 60%, whereas applications at 7 m s-1 yielded 13% to 22% coverage. Coverage consistently decreased as application speed increased across all nozzles, with extended-range flat-spray nozzles declining at a faster rate than air-induction nozzles, likely due to higher drift. Experiments measuring the drift potential of UAV-applied pesticides using extended-range flat spray, air-induction flat-spray, turbo air-induction flat-spray, and hollow-cone nozzles under 0, 2, 4, 7, and 9 m s-1 perpendicular wind conditions in the immediate 1.75 m above the target were conducted in the absence of natural wind. Off-target movement was observed under all perpendicular wind conditions with all nozzles tested but was nondetectable beyond 5 m away from the target. Coverage from all nozzles exhibited a concave-shaped curve in response to the increasing perpendicular wind speed due to turbulence. The maximum target coverage in drift studies was observed when the perpendicular wind was 0 and 8.94 m s-1, but higher turbulence at the two highest perpendicular wind speeds (6.71 and 8.94 m s-1) increased coverage variability, whereas the lowest variability was observed at 2.24 m s-1 wind speed. Results suggested that air-induction flat-spray and turbo air-induction flat-spray nozzles and an application speed of 3 m s-1 provided an adequate coverage of target areas while minimizing off-target movement risk.},
author = {Hunter, Joseph E. and Gannon, Travis W. and Richardson, Robert J. and Yelverton, Fred H. and Leon, Ramon G.},
doi = {10.1017/wet.2019.101},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Hunter et al. - 2020 - Coverage and drift potential associated with nozzle and speed selection for herbicide applications using an unman.pdf:pdf},
issn = {15502740},
journal = {Weed Technology},
keywords = {Droplet,Off-target,Pesticide application,Precision agriculture,Site-specific,UAV},
mendeley-groups = {UAV,Precision Agriculture},
month = {apr},
number = {2},
pages = {235--240},
publisher = {Cambridge University Press},
title = {{Coverage and drift potential associated with nozzle and speed selection for herbicide applications using an unmanned aerial sprayer}},
url = {www.cambridge.org/wet},
volume = {34},
year = {2020}
}
@article{Yu2020,
abstract = {Spot spraying POST herbicides is an effective approach to reduce herbicide input and weed control cost. Machine vision detection of grass or grass-like weeds in turfgrass systems is a challenging task due to the similarity in plant morphology. In this work, we explored the feasibility of using image classification with deep convolutional neural networks (DCNN), including AlexNet, GoogLeNet, and VGGNet, for detection of crabgrass species (Digitaria spp.), doveweed [Murdannia nudiflora (L.) Brenan], dallisgrass (Paspalum dilatatum Poir.), and tropical signalgrass [Urochloa distachya (L.) T.Q. Nguyen] in bermudagrass [Cynodon dactylon (L.) Pers.]. VGGNet generally outperformed AlexNet and GoogLeNet in detecting selected grassy weeds. For detection of P. dilatatum, VGGNet achieved high F1 scores (≥0.97) and recall values (≥0.99). A single VGGNet model exhibited high F1 scores (≥0.93) and recall values (1.00) that reliably detected Digitaria spp., M. nudiflora, P. dilatatum, and U. distachya. Low weed density reduced the recall values of AlexNet at detecting all weed species and GoogLeNet at detecting Digitaria spp. In comparison, VGGNet achieved excellent performances (overall accuracy = 1.00) at detecting all weed species in both high and low weed-density scenarios. These results demonstrate the feasibility of using DCNN for detection of grass or grass-like weeds in turfgrass systems.},
author = {Yu, Jialin and Schumann, Arnold W. and Sharpe, Shaun M. and Li, Xuehan and Boyd, Nathan S.},
doi = {10.1017/wsc.2020.46},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Yu et al. - 2020 - Detection of grassy weeds in bermudagrass with deep convolutional neural networks.pdf:pdf},
issn = {15502759},
journal = {Weed Science},
keywords = {Artificial intelligence,Keywords:,computer vision,machine vision,precision herbicide application,weed recognition},
mendeley-groups = {Image Classification,Weed Control,Precision Agriculture,AI},
number = {5},
pages = {545--552},
publisher = {Cambridge University Press},
title = {{Detection of grassy weeds in bermudagrass with deep convolutional neural networks}},
url = {www.cambridge.org/wsc},
volume = {68},
year = {2020}
}
@article{Sapkota2020,
abstract = {<p>In recent years, Unmanned Aerial Systems (UAS) have emerged as an innovative technology to provide spatio-temporal information about weed species in crop fields. Such information is a critical input for any site-specific weed management program. A multi-rotor UAS (Phantom 4) equipped with an RGB sensor was used to collect imagery in three bands (Red, Green, and Blue; 0.8 cm/pixel resolution) with the objectives of (a) mapping weeds in cotton and (b) determining the relationship between image-based weed coverage and ground-based weed densities. For weed mapping, three different weed density levels (high, medium, and low) were established for a mix of different weed species, with three replications. To determine weed densities through ground truthing, five quadrats (1 m × 1 m) were laid out in each plot. The aerial imageries were preprocessed and subjected to Hough transformation to delineate cotton rows. Following the separation of inter-row vegetation from crop rows, a multi-level classification coupled with machine learning algorithms were used to distinguish intra-row weeds from cotton. Overall, accuracy levels of 89.16%, 85.83%, and 83.33% and kappa values of 0.84, 0.79, and 0.75 were achieved for detecting weed occurrence in high, medium, and low density plots, respectively. Further, ground-truthing based overall weed density values were fairly correlated (r2 = 0.80) with image-based weed coverage assessments. Among the specific weed species evaluated, Palmer amaranth (Amaranthus palmeri S. Watson) showed the highest correlation (r2 = 0.91) followed by red sprangletop (Leptochloa mucronata Michx) (r2 = 0.88). The results highlight the utility of UAS-borne RGB imagery for weed mapping and density estimation in cotton for precision weed management.</p>},
author = {Sapkota, Bishwa and Singh, Vijay and Cope, Dale and Valasek, John and Bagavathiannan, Muthukumar},
doi = {10.3390/agriengineering2020024},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Sapkota et al. - 2020 - Mapping and Estimating Weeds in Cotton Using Unmanned Aerial Systems-Borne Imagery.pdf:pdf},
issn = {2624-7402},
journal = {AgriEngineering},
keywords = {Hough transformation,digital agronomy,machine learning,object-based image analysis,precision agriculture},
mendeley-groups = {UAV,Image Processing,Weed Control,Precision Agriculture},
month = {jun},
number = {2},
pages = {350--366},
publisher = {MDPI AG},
title = {{Mapping and Estimating Weeds in Cotton Using Unmanned Aerial Systems-Borne Imagery}},
url = {https://www.mdpi.com/2624-7402/2/2/24},
volume = {2},
year = {2020}
}
@inproceedings{Ampatzidis2019,
abstract = {Current breeding methods are based on phenotypic recurrent selection (PRS), which require at least 15 years to develop, select and release new cultivars. New breeding methods, such as genomic selection, incorporate genomics, statistical and computational tools, and allow the acceleration of cultivar development. A key requirement for implementing GS is the creation of a large and genetically diverse training population. Hence, large-scale experiments in plant phenotyping are critical, because the accurate and rapid acquisition of phenotypic data is important for exploring the correlation between genomic and phenotypic information. Traditional sensing technologies for evaluation of field's phenotypes rely on manual sampling and are often very labor intensive and time consuming, especially when covering large areas. Small unmanned aerial vehicles (UAVs) equipped with various sensors have recently become flexible and cost-effective solutions for fast, precise and non-destructive high-throughput phenotyping. Herein, we present a methodology for data acquisition and processing utilizing small UAVs, multi-spectral imaging and artificial intelligence (deep learning based machine vision) to evaluate phenotypic characteristics on specialty crops. This low-cost, and automated methodology utilizes artificial intelligence (AI) and machine learning (ML) to: (i) detect, count and geo-locate plants; (ii) categorize plants based on their canopy size and height; (iii) develop individual plant health status maps; and (iv) predict yield and crop load. As an example, the proposed methodology was able to detect and count citrus trees, in a grove of 4,440 trees, with accuracy of 99.9%, and estimate their canopy size with overall accuracy of 97%.},
address = {St. Joseph, MI},
author = {Ampatzidis, Yiannis and Partel, Victor},
booktitle = {2019 Boston, Massachusetts July 7- July 10, 2019},
doi = {10.13031/aim.201900293},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Ampatzidis, Partel - 2019 - &amplti&ampgtUAV-based high throughput phenotyping in specialty crops utilizing artificial intelligence&ampl.pdf:pdf},
keywords = {Artificial intelligence,Deep learning,Machine learning,Neural networks,Precision agriculture,UAV},
mendeley-groups = {UAV,Precision Agriculture,AI},
pages = {1--},
publisher = {American Society of Agricultural and Biological Engineers},
title = {{UAV-based high throughput phenotyping in specialty crops utilizing artificial intelligence}},
url = {http://elibrary.asabe.org/abstract.asp?JID=5&AID=50273&CID=bos2019&T=1},
year = {2019}
}
@article{Ji2021,
abstract = {<p> <bold>HIGHLIGHTS</bold> </p>},
author = {Ji, Jiangtao and Zhu, Xu and Ma, Hao and Wang, Hui and Jin, Xin and Zhao, Kaixuan},
doi = {10.13031/aea.14041},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Ji et al. - 2021 - Apple Fruit Recognition Based on a Deep Learning Algorithm Using an Improved Lightweight Network.pdf:pdf},
issn = {1943-7838},
journal = {Applied Engineering in Agriculture},
keywords = {Apple recognition,Compound scaling,Deep learning algorithm,Lightweight network,Yield estimation},
mendeley-groups = {Object Detection,AI},
number = {1},
pages = {123--134},
publisher = {American Society of Agricultural and Biological Engineers},
title = {{Apple Fruit Recognition Based on a Deep Learning Algorithm Using an Improved Lightweight Network}},
url = {https://elibrary.asabe.org/abstract.asp?AID=52037&t=3&dabs=Y&redir=&redirType=},
volume = {37},
year = {2021}
}
@inproceedings{Cheng2019,
abstract = {Tomato late blight is an infamous disease due to causing severe tomato yield loss. Phytophthora infestans, the causal pathogen of tomato late blight, could disseminate to all the cultivation regions in a suitable weather condition and destroy all the crop in weeks. In order to prevent severe disease spreading, early symptom identification of the disease is important to take actions for disease control. Late blight symptoms include from irregularly shaped water-soaked to brown necrotic lesions on plant leaves and stems. Conventionally, the identification of late blight deeply relies on the experience of tomato farmers. However, the symptoms of late blight might be confused with the atypical symptoms and lesions of some other diseases, confusing not only the well-experienced farmers but also the inexperienced plant pathologists. This study proposed to identify tomato late blight using leaf images and deep learning. A Navigator-teacher-scrutinizer network (NTS-Net) was developed to localize and identify the putative late blight lesions of tomato leaves. The developed NTS-Net model achieved a mean accuracy of 99.76% in diseased and healthy plant identification and also achieved a precision of 50% in lesions localization.},
address = {St. Joseph, MI},
author = {Cheng, Hsueh-Hung and Ke, Yan-Ling and Lin, Chu-Ping and Huang, Jin-Hsing and Chen, Shih-Fang and Kuo, Yan-Fu},
booktitle = {2019 Boston, Massachusetts July 7- July 10, 2019},
doi = {10.13031/aim.201900445},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Cheng et al. - 2019 - Identifying and Localizing the Disease Spots of Late Blight on Tomato Leaves Using Deep Convolutional Neural Netwo.pdf:pdf},
keywords = {Deep learning,Disease identification,Navigator-teacher-scrutinizer network,Tomato late blight},
mendeley-groups = {Unsupervised,Disease Identificaiton,AI},
pages = {1--},
publisher = {American Society of Agricultural and Biological Engineers},
title = {{Identifying and Localizing the Disease Spots of Late Blight on Tomato Leaves Using Deep Convolutional Neural Networks}},
url = {http://elibrary.asabe.org/abstract.asp?JID=5&AID=50730&CID=bos2019&T=1},
year = {2019}
}
@inproceedings{Fue2018,
abstract = {Robotic harvesting involves navigation and environmental perception as first operations before harvesting of the bolls can commence. Navigation is the distance required for a harvester's arm to reach the cotton boll while perception is the position of the boll relative to surrounding environment. These two operations give a 3D position of the cotton boll for picking and can only be achieved by detection and tracking of the cotton bolls in real-time. It means detection, tracking and counting of cotton bolls using a moving camera allows the robotic machine to harvest easily. GPU-accelerated deep neural networks were used to train the convolution networks for detection of cotton bolls. It was achieved by using pretrained tiny yolo weights and DarkFlow, a framework which translates YOLOv2 darknet neural networks to TensorFlow. A method to connect tracklets using vectors that are predicted using Lucas-Kanade algorithm and optimized using robust L-estimators and homography transformation is proposed. The system was tested in defoliated cotton plants during the spring of 2018. Using three video treatments, the counting performance accuracy was around 93% with standard deviation 6%. The system average processing speed was 21 fps in desktop computer and 3.9 fps in embedded system. Detection of the system achieved an accuracy and sensitivity of 93% while precision was 99.9% and F1 score was 1. The Tukey's test showed that the system accuracy and sensitivity was the same when the plants were rearranged. This performance is crucial for real-time robot decisions that also measure yield while harvesting.},
address = {St. Joseph, MI},
author = {Fue, Kadeghe G and Porter, Wesley M and Rains, Glen C},
booktitle = {2018 Detroit, Michigan July 29 - August 1, 2018},
doi = {10.13031/aim.201800831},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Fue, Porter, Rains - 2018 - Deep Learning based Real-time GPU-accelerated Tracking and Counting of Cotton Bolls under Field Conditions u.pdf:pdf},
keywords = {Boll counting,CNN,Cotton Bolls,Cotton counting,Cotton harvesting,DarkFlow,Darknet,Deep learning,GPU,Machine vision,TensorFlow,YOLO},
mendeley-groups = {Object Detection,AI},
pages = {1--},
publisher = {American Society of Agricultural and Biological Engineers},
title = {{Deep Learning based Real-time GPU-accelerated Tracking and Counting of Cotton Bolls under Field Conditions using a Moving Camera}},
url = {http://elibrary.asabe.org/abstract.asp?JID=5&AID=49298&CID=det2018&T=1},
year = {2018}
}
@article{Cruz2017,
abstract = {Xylella fastidiosa is a bacterial pathogen responsible for Pierce's Disease (PD) in Vitus vinifera L. Infections of PD remain a problem, despite efforts by the CFDA and USDA to control the disease vector. In 2014, PD caused $104.4 million losses to Californian wine and table grape growers. This work details a system to detect PD automatically by computers. The proposed system can provide early screening to improve reaction time of control strategies because it can be deployed earlier than conventional lab tests and at a lower cost. Due to xylem localization, petioles are collected for testing after leaf blades have dried. This causes delays and further contamination of neighboring vines. However, PD infected vines display leaf scorching which can be automatically identified from leaf clippings three to eighteen months after initial infection. Preliminary results with a prototype deep learning system (AlexNet) have a sensitivity of 98.99%. We are the first to automate grapevine PD detection with deep learning algorithms. When implemented on hand-held diagnostic tools, the technologies pioneered in this program can accelerate a response to mitigate crop losses of other diseases such as phony peach disease, citrus variegated chlorosis, and others.},
author = {Cruz, Albert C and El-Kereamy, Ashraf and Ampatzidis, Yiannis},
doi = {10.13031/aim.201800148},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Cruz, El-Kereamy, Ampatzidis - 2017 - Vision-based Grapevine Pierce's disease detection system using artificial intelligence.pdf:pdf},
journal = {elibrary.asabe.org},
keywords = {Pierce's Disease,Vitus vinifera L,artificial intelligence,deep learning,machine learning},
mendeley-groups = {Image Classification,Disease Identificaiton,AI},
title = {{Vision-based Grapevine Pierce's disease detection system using artificial intelligence}},
url = {https://doi.org/10.13031/aim.201800148},
year = {2017}
}
@article{Kumar2020,
abstract = {Crop damage during the intra-row weed eradiation is one of the biggest challenges in intercultural agricultural operations. Several available mechanical systems provide effective weeding but result in excess crop damage. On the other hand, chemical based systems have been raising serious environmental and food concerns. This study presents development of a cost-effective mechatronic prototype for intra-row weeding operation. The primary focus was on incurring minimal crop damage. The system integrates time of flight and inductive sensing into fuzzy logic algorithm for electronic control of a four-bar linkage mechanism (FBLM). The crank of FBLM was connected to the vertical rotary weed control shaft with weeding blades. The crop sensing triggers the electronic control to laterally shift the control shaft away from crop, proportional to the forward speed and soil conditions. The developed algorithm incorporates varied conditions of soil, forward speed, and plant spacing to calculate dynamic lateral shift speed (SRPM). The prototype was evaluated to determine the relationships between the operating conditions and electronic control parameters. Moreover, the plant damage was assessed under varied conditions of plant spacing, forward speeds, soil cone index, operational depth and electronic control parameters. The derived SRPM was established as the ultimate governing factor for avoiding crop damage that varied significantly with electronic response time and soil strength (P < 0.05). Plant damage increased significantly under higher forward speeds and lower plant spacing (P < 0.05). Preliminary field evaluation of the developed prototype showed a significant potential of this system for effective control on weeds (>65%) and crop damage (<25%).},
author = {Kumar, Satya Prakash and Tewari, V.K. and Chandel, Abhilash K. and Mehta, C.R. and Nare, Brajesh and Chethan, C.R. and Mundhada, Kaustubh and Shrivastava, Prateek and Gupta, Chanchal and Hota, Smrutilipi},
doi = {10.1016/j.aiia.2020.06.004},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Kumar et al. - 2020 - A fuzzy logic algorithm derived mechatronic concept prototype for crop damage avoidance during eco-friendly eradic.pdf:pdf},
issn = {25897217},
journal = {Artificial Intelligence in Agriculture},
mendeley-groups = {Weed Control},
month = {jan},
pages = {116--126},
publisher = {Elsevier BV},
title = {{A fuzzy logic algorithm derived mechatronic concept prototype for crop damage avoidance during eco-friendly eradication of intra-row weeds}},
volume = {4},
year = {2020}
}
@misc{Camacho2018,
abstract = {Machine learning, a collection of data-analytical techniques aimed at building predictive models from multi-dimensional datasets, is becoming integral to modern biological research. By enabling one to generate models that learn from large datasets and make predictions on likely outcomes, machine learning can be used to study complex cellular systems such as biological networks. Here, we provide a primer on machine learning for life scientists, including an introduction to deep learning. We discuss opportunities and challenges at the intersection of machine learning and network biology, which could impact disease biology, drug discovery, microbiome research, and synthetic biology. Machine-learning approaches are essential for pulling information out of the vast datasets that are being collected across biology and biomedicine. This Review considers the opportunities and challenges at the intersection of network biology and data science.},
author = {Camacho, Diogo M. and Collins, Katherine M. and Powers, Rani K. and Costello, James C. and Collins, James J.},
booktitle = {Cell},
doi = {10.1016/j.cell.2018.05.015},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Camacho et al. - 2018 - Next-Generation Machine Learning for Biological Networks.pdf:pdf},
issn = {10974172},
keywords = {Machine leaning,deep learning,network biology,neural networks,synthetic biology,systems biology},
number = {7},
pages = {1581--1592},
title = {{Next-Generation Machine Learning for Biological Networks}},
volume = {173},
year = {2018}
}
@inproceedings{Sabour2017,
abstract = {A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or an object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-the-art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule.},
author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Sabour, Frosst, Hinton - Unknown - Dynamic Routing Between Capsules.pdf:pdf},
issn = {10495258},
pages = {3857--3867},
title = {{Dynamic routing between capsules}},
volume = {2017-Decem},
year = {2017}
}
@book{sylvester2018agriculture,
author = {Sylvester, Gerard},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Unknown - Unknown - E-agriculture in Action Drones for Agriculture.pdf:pdf},
mendeley-groups = {UAV,Precision Agriculture},
publisher = {Food and Agriculture Organization ofn the United Nations and International$\sim${\ldots}},
title = {{E-agriculture in action: Drones for agriculture}},
year = {2018}
}
@article{OGrady2019,
abstract = {Establishing food security remains a global challenge; it is thus a specific objective of the United Nations Sustainable Development Goals for 2030. Successfully delivering productive and sustainable agricultural systems worldwide will form the foundations for overcoming this challenge. Smart agriculture is often perceived as one key enabler when considering the twin objectives of eliminating world hunger and undernourishment. The practical realization, deployment, and adoption of smart agricultural systems remain distant due to a confluence of technological, social, and economic factors. Edge computing offers a potentially tractable model for mainstreaming smart agriculture. A synergistic relationship exists, which, if harnessed productively, would increase the penetration of smart agricultural technologies across Majority-Minority world boundaries. The paper considers the prevailing context of global food security, smart agriculture and the pervasive issue of internet access. A survey of the state-of-the-art in research utilizing the Edge model of computing in agriculture is reported. Results of the survey confirm that the Edge model is actively explored in a number of agricultural domains. However, research is rooted in the prototype stage, and detailed studies are currently lacking. While potential is demonstrated, several systemic challenges must be addressed to manifest meaningful impact at the farm level. 食糧安全保障の確立は依然として世界的な課題であり、2030 年に向けた国連の持続可能な開発目標の具体的な目標となっている。生産性が高く持続可能な農業システムを世界中で成功させることは、この課題を克服するための基盤を形成することになる。スマート農業は、世界の飢餓と栄養不足をなくすという双子の目標を考えるとき、重要な実現要因の一つとして認識されることが多い。しかし、技術的、社会的、経済的な要因が重なり合っているため、スマート農業システムの実用化、展開、採用はまだ遠い状況にあります。エッジコンピューティングは、スマート農業の主流化に向けて、扱いやすいモデルを提供する可能性があります。相乗効果のある関係が存在し、これを生産的に利用すれば、マジョリティ・マイナーの世界の境界を越えてスマート農業技術の普及を促進することができます。本論文では、世界的な食糧安全保障、スマート農業、インターネットへのアクセスの普及という現在の状況を考察している。また、農業におけるコンピューティングのエッジモデルを活用した研究の最先端の調査を報告する。調査の結果、多くの農業分野でEdgeモデルが積極的に研究されていることが確認された。しかし、研究はプロトタイプの段階にとどまっており、詳細な研究は現在のところ行われていない。潜在的な可能性は示されているが、農場レベルで意味のあるインパクトを与えるためには、いくつかの体系的な課題に対処しなければならない。},
author = {O'Grady, M.J. and Langton, D. and O'Hare, G.M.P.},
doi = {10.1016/j.aiia.2019.12.001},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/O'Grady, Langton, O'Hare - 2019 - Edge computing A tractable model for smart agriculture.pdf:pdf},
issn = {25897217},
journal = {Artificial Intelligence in Agriculture},
mendeley-groups = {Edge Computing,Precision Agriculture,AI},
month = {sep},
pages = {42--51},
publisher = {Elsevier BV},
title = {{Edge computing: A tractable model for smart agriculture?}},
volume = {3},
year = {2019}
}
@inproceedings{Dokic2020,
abstract = {In the last two decades, we have witnessed the intensive development of artificial intelligence in the field of agriculture. In this period, the transition from the application of simpler machine learning algorithms to the application of deep learning algorithms can be observed. This paper provides a quantitative overview of papers published in the past two decades, thematically related to machine learning, neural networks, and deep learning. Also, a review of the contribution of individual countries was given. The second part of the paper analyses trends in the first half of the current year, with an emphasis on areas of application, selected deep learning methods, input data, crop mentioned in the paper and applied frameworks. Scopus and Web of Science citation databases were used.},
author = {Dokic, K. and Blaskovic, L. and Mandusic, D.},
booktitle = {IOP Conference Series: Earth and Environmental Science},
doi = {10.1088/1755-1315/614/1/012138},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Dokic, Blaskovic, Mandusic - 2020 - From machine learning to deep learning in agriculture-the quantitative review of trends.pdf:pdf},
issn = {17551315},
mendeley-groups = {UAV,Precision Agriculture,Review Paper,AI},
month = {dec},
number = {1},
pages = {12138},
publisher = {IOP Publishing Ltd},
title = {{From machine learning to deep learning in agriculture-the quantitative review of trends}},
url = {https://iopscience.iop.org/article/10.1088/1755-1315/614/1/012138 https://iopscience.iop.org/article/10.1088/1755-1315/614/1/012138/meta},
volume = {614},
year = {2020}
}
@inproceedings{Cruz2017a,
abstract = {We have developed a vision-based system to detect symptoms of leaf scorch on leaves of Olea europaea L. infected by Xylella fastidiosa. Previous works predicted disease from leaf images with deep learning but required a vast amount of data. Crowd sourcing generated the required amount of data (PlantVillage project), but this has limited applicability to commercial species that are inaccessible for laypeople to photograph and diseases that require an expert to detect. In this paper, we demonstrate that transfer learning can be leveraged when it is not possible to collect thousands of new leaf images. Transfer learning is the re-application of an already trained deep learner to a new problem. We present a novel algorithm to fuse the data at different levels of abstraction to improve convergence of transfer learning. The algorithm discovers low-level features from raw data to automatically detect veins and colors that lead to symptomatic leaves. Leaf scorch is detected with a true positive rate of 98.60 ± 1.47%. Experiment included 100 control, 99 leaf scorch and 100 abiotic stress images. Results were obtained with a convolutional neural network trained with the stochastic gradient descent method. This work shows potential for early, automatic, quantitative detection of disease in plants with reduced diagnosis time and cost.},
address = {St. Joseph, MI},
author = {Cruz, Albert C and Luvisi, Andrea and {De Bellis}, Luigi and Ampatzidis, Yiannis},
booktitle = {2017 Spokane, Washington July 16 - July 19, 2017},
doi = {10.13031/aim.201700241},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Cruz et al. - 2017 - &amplti&ampgtVision-Based Plant Disease Detection System Using Transfer and Deep Learning&amplti&ampgt.pdf:pdf},
keywords = {Convolutional neural networks,Deep learning,Machine vision,Olea europaea L.,Transfer learning,Xylella fastidiosa},
mendeley-groups = {Image Classification,Disease Identificaiton,AI},
pages = {1--},
publisher = {American Society of Agricultural and Biological Engineers},
title = {{Vision-Based Plant Disease Detection System Using Transfer and Deep Learning}},
url = {http://elibrary.asabe.org/abstract.asp?JID=5&AID=47834&CID=spo2017&T=1},
year = {2017}
}
@article{Su2020,
abstract = {The continued emergence of herbicide-resistant weeds and the increasing labor costs are threatening the ability of growers to manage weeds and maintain profits. The smart farm with the advantage of non-invasive and high-efficiency operation plays an important role in increasing the sustainability of agricultural system as it can optimize crop inputs such as herbicides while preserving resources including soil and water. An automatic weed control system requires a sensing subsystem capable of detecting and distinguishing crop plants from weeds. The overlapping plants remain a challenge for successful detection of weeds. Crop plant signaling is a new robot-plant interaction technique that allows the visualization of exogenous fluorescent signals applied to crop plants for crop/weed identification. Based on all published articles in the leading edge of knowledge, a comprehensive review of the mushrooming crop plant signaling for discriminations of weeds and crops is highlighted. The discussion outlines the significant progress that has been made in developing new and more robust automated systems along with the current challenges and future prospects. This paper details the promise of crop plant signaling for accurate and automated plant recognitions in cropping systems. There is no doubt that this review is of great significance to scholars in related research field to study the solutions to real-time weed control.},
author = {Su, Wen-Hao},
doi = {10.1016/j.aiia.2020.11.001},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Su - 2020 - Crop plant signaling for real-time plant identification in smart farm A systematic review and new concept in artificial inte.pdf:pdf},
issn = {25897217},
journal = {Artificial Intelligence in Agriculture},
mendeley-groups = {Weed Control,AI},
month = {jan},
pages = {262--271},
publisher = {Elsevier BV},
title = {{Crop plant signaling for real-time plant identification in smart farm: A systematic review and new concept in artificial intelligence for automated weed control}},
volume = {4},
year = {2020}
}
@article{Borra-Serrano2015,
abstract = {Unmanned aerial vehicles (UAVs) combined with different spectral range sensors are an emerging technology for providing early weed maps for optimizing herbicide applications. Considering that weeds, at very early phenological stages, are similar spectrally and in appearance, three major components are relevant: spatial resolution, type of sensor and classification algorithm. Resampling is a technique to create a new version of an image with a different width and/or height in pixels, and it has been used in satellite imagery with different spatial and temporal resolutions. In this paper, the efficiency of resampled-images (RS-images) created from real UAV-images (UAV-images; the UAVs were equipped with two types of sensors, i.e., visible and visible plus near-infrared spectra) captured at different altitudes is examined to test the quality of the RS-image output. The performance of the object-based-image-analysis (OBIA) implemented for the early weed mapping using different weed thresholds was also evaluated. Our results showed that resampling accurately extracted the spectral values from high spatial resolution UAV-images at an altitude of 30 m and the RS-image data at altitudes of 60 and 100 m, was able to provide accurate weed cover and herbicide application maps compared with UAV-images from real flights.},
author = {Borra-Serrano, Irene and Pe{\~{n}}a, Jos{\'{e}} and Torres-S{\'{a}}nchez, Jorge and Mesas-Carrascosa, Francisco and L{\'{o}}pez-Granados, Francisca},
doi = {10.3390/s150819688},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Borra-Serrano et al. - 2015 - Spatial Quality Evaluation of Resampled Unmanned Aerial Vehicle-Imagery for Weed Mapping.pdf:pdf},
issn = {1424-8220},
journal = {Sensors},
keywords = {Near-infrared (NIR),OBIA,Ortho-mosaicked image,Resampling,UAV,Visible (RGB),Weed mapping},
mendeley-groups = {UAV,Early Season Weed,Weed Control,Precision Agriculture},
month = {aug},
number = {8},
pages = {19688--19708},
publisher = {MDPI AG},
title = {{Spatial Quality Evaluation of Resampled Unmanned Aerial Vehicle-Imagery for Weed Mapping}},
url = {http://www.mdpi.com/1424-8220/15/8/19688},
volume = {15},
year = {2015}
}
@incollection{Singh2020,
abstract = {Modern precision weed management relies on site-specific management tactics to maximize resource use efficiency and yield, while reducing unintended environmental impacts caused by herbicides. Scouting for weeds is an important activity to assist weed management decision making, and has been carried out by trained specialists through extensive and routine visual examination of the fields. Recent advancements in Unmanned Aircraft Systems (UAS)-based tools and geospatial information technology have created enormous applications for efficient and economical assessment of weed infestations as well as site-specific weed management. The utilization of UAS-based technologies for weed management applications is currently in its infancy, but this field has witnessed rapid growth in recent times in terms of aerial data acquisition and analysis. Challenges exist in UAS platform reliability, sensor capability and integration, image pre-processing, quantitative assessment and prediction, final product development, and product delivery. This review summarizes current knowledge on the utility of UAS platforms and remote sensing tools for weed scouting and precision weed management. Further, it critically examines potential opportunities and limitations to current UAS technologies, with particular emphasis on the lessons learned from UAS-based weed management research conducted at Texas A&M University.},
author = {Singh, Vijay and Rana, Aman and Bishop, Michael and Filippi, Anthony M. and Cope, Dale and Rajan, Nithya and Bagavathiannan, Muthukumar},
booktitle = {Advances in Agronomy},
doi = {10.1016/bs.agron.2019.08.004},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Singh et al. - 2020 - Unmanned aircraft systems for precision weed detection and management Prospects and challenges.pdf:pdf},
isbn = {9780128204597},
issn = {00652113},
keywords = {Remote sensing,Sensors,Site-specific weed management,Spectral reflectance,UAVs,Weed scouting and monitoring},
mendeley-groups = {UAV,Weed Control,Precision Agriculture,Review Paper,AI},
month = {jan},
pages = {93--134},
publisher = {Academic Press Inc.},
title = {{Unmanned aircraft systems for precision weed detection and management: Prospects and challenges}},
volume = {159},
year = {2020}
}
@article{Lopez-Granados2016,
abstract = {Sorghum halepense (johnsongrass) is a perennial weed with a vegetative reproductive system and one of the most competitive weeds in maize showing a spatial distribution in compact patches. When maize is irrigated, successive weed emergences occur in the early phenological phases of the crop, which require several herbicide applications. Our aim was to provide an accurate tool for an early detection and mapping of johnsongrass patches and delineate the actual surface area requiring a site-specific herbicide treatment based on the weed coverage. This early detection represents a major challenge in actual field scenarios because both species are in the Poaceae family, and show analogous spectral patterns, an extraordinarily similar appearance and a parallel phenological evolution. To solve this, an automatic OBIA (object-based-image-analysis) procedure was developed to be applied on orthomosaicked images using visible (red-green-blue bands) and multispectral (red-green-blue and near infrared bands) cameras collected by an unmanned aerial vehicle (UAV) that flew at altitudes of 30, 60 and 100 m on two maize fields. One of our first phases was the generation of accurate orthomosaicked images of an herbaceous crop such as maize, which presented a repetitive pattern and nearly no invariant parameters to conduct the aerotriangulation. Here, we show that high-quality orthomosaicks were produced from both cameras and that they were able to be the first step for mapping the johnsongrass patches. The most accurate weed maps were obtained using the multispectral camera at an altitude of 30 m in both fields. These maps were then used to design a site-specific weed management program, and we demonstrated that potential herbicide savings ranged from 85 to 96 %. Our results showed that accurate and timely maps of johnsongrass patches in maize can be a key element in achieving site-specific and sustainable herbicide applications for reducing spraying herbicides and costs.},
author = {L{\'{o}}pez-Granados, Francisca and Torres-S{\'{a}}nchez, Jorge and {De Castro}, Ana Isabel and Serrano-P{\'{e}}rez, Ang{\'{e}}lica and Mesas-Carrascosa, Francisco Javier and Pe{\~{n}}a, Jos{\'{e}} Manuel},
doi = {10.1007/s13593-016-0405-7},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/L{\'{o}}pez-Granados et al. - 2016 - Object-based early monitoring of a grass weed in a grass crop using high resolution UAV imagery.pdf:pdf},
issn = {17730155},
journal = {Agronomy for Sustainable Development},
keywords = {Corn,Drone,Johnsongrass,Maize,OBIA,Precision agriculture,Site-specific herbicide,Sorghum halepense,UAS,Weed detection and mapping},
mendeley-groups = {UAV,Image Processing,Early Season Weed},
month = {dec},
number = {4},
pages = {1--12},
publisher = {Springer-Verlag France},
title = {{Object-based early monitoring of a grass weed in a grass crop using high resolution UAV imagery}},
url = {https://link.springer.com/article/10.1007/s13593-016-0405-7},
volume = {36},
year = {2016}
}
@article{Louargant2018,
abstract = {In agriculture, reducing herbicide use is a challenge to reduce health and environmental risks while maintaining production yield and quality. Site-specific weed management is a promising way to reach this objective but requires efficient weed detection methods. In this paper, an automatic image processing has been developed to discriminate between crop and weed pixels combining spatial and spectral information extracted from four-band multispectral images. Image data was captured at 3 m above ground, with a camera (multiSPEC 4C, AIRINOV, Paris) mounted on a pole kept manually. For each image, the field of view was approximately 4 m × 3 m and the resolution was 6 mm/pix. The row crop arrangement was first used to discriminate between some crop and weed pixels depending on their location inside or outside of crop rows. Then, these pixels were used to automatically build the training dataset concerning the multispectral features of crop and weed pixel classes. For each image, a specific training dataset was used by a supervised classifier (Support Vector Machine) to classify pixels that cannot be correctly discriminated using only the initial spatial approach. Finally, inter-row pixels were classified as weed and in-row pixels were classified as crop or weed depending on their spectral characteristics. The method was assessed on 14 images captured on maize and sugar beet fields. The contribution of the spatial, spectral and combined information was studied with respect to the classification quality. Our results show the better ability of the spatial and spectral combination algorithm to detect weeds between and within crop rows. They demonstrate the improvement of the weed detection rate and the improvement of its robustness. On all images, the mean value of the weed detection rate was 89% for spatial and spectral combination method, 79% for spatial method, and 75% for spectral method. Moreover, our work shows that the plant in-line sowing can be used to design an automatic image processing and classification algorithm to detect weed without requiring any manual data selection and labelling. Since the method required crop row identification, the method is suitable for wide-row crops and high spatial resolution images (at least 6 mm/pix).},
author = {Louargant, Marine and Jones, Gawain and Faroux, Romain and Paoli, Jean-No{\"{e}}l and Maillot, Thibault and G{\'{e}}e, Christelle and Villette, Sylvain},
doi = {10.3390/rs10050761},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Louargant et al. - 2018 - Unsupervised Classification Algorithm for Early Weed Detection in Row-Crops by Combining Spatial and Spectral.pdf:pdf},
issn = {2072-4292},
journal = {Remote Sensing},
keywords = {Automatic training data set generation,Image processing,Multispectral information,SVM,Spatial information,Weed detection},
mendeley-groups = {Early Season Weed,Image Processing,Weed Control,Precision Agriculture},
month = {may},
number = {5},
pages = {761},
publisher = {MDPI AG},
title = {{Unsupervised Classification Algorithm for Early Weed Detection in Row-Crops by Combining Spatial and Spectral Information}},
url = {http://www.mdpi.com/2072-4292/10/5/761},
volume = {10},
year = {2018}
}
@article{Fue2021,
abstract = {<p> <bold>Highlights</bold> </p>},
author = {Fue, Kadeghe G. and Porter, Wesley M. and Barnes, Edward M. and Rains, Glen C.},
doi = {10.13031/trans.13112},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Fue et al. - 2021 - Ensemble Method of Deep Learning, Color Segmentation, and Image Transformation to Track, Localize, and Count Cotton.pdf:pdf},
issn = {2151-0040},
journal = {Transactions of the ASABE},
keywords = {Boll counting,Cotton,Cotton harvesting,DarkFlow,Darknet,Deep learning,Machine vision,YOLOv2},
mendeley-groups = {Object Detection,Edge Computing,AI},
number = {1},
pages = {341--352},
publisher = {American Society of Agricultural and Biological Engineers},
title = {{Ensemble Method of Deep Learning, Color Segmentation, and Image Transformation to Track, Localize, and Count Cotton Bolls Using a Moving Camera in Real-Time}},
url = {https://elibrary.asabe.org/abstract.asp?AID=52062&t=3&dabs=Y&redir=&redirType=},
volume = {64},
year = {2021}
}
@article{Fennimore2019,
abstract = {Specialty crop herbicides are not a priority for the agrochemical industry, and many of these crops do not have access to effective herbicides. High-value fruit and vegetable crops represent small markets and high potential liability in the case of herbicide-induced crop damage. Meanwhile, conventional and organic specialty crop producers are experiencing labor shortages and higher manual weeding costs. Robotic weeders are promising new weed control tools for specialty crops, because they are cheaper to develop and, with fewer environmental and human health risks, are less regulated than herbicides. Now is the time for greater investment in robotic weeders as new herbicides are expensive to develop and few in number, organic crops need better weed control technology and governments are demanding reduced use of pesticides. Public funding of fundamental research on robotic weeder technology can help improve weed and crop recognition, weed control actuators, and expansion of weed science curricula to train students in this technology. Robotic weeders can expand the array of tools available to specialty crop growers. However, the development of robotic weeders will require a broader recognition that these tools are a viable path to create new weed control tools for specialty crops. {\textcopyright} 2019 Society of Chemical Industry.},
author = {Fennimore, Steven A. and Cutulle, Matthew},
doi = {10.1002/ps.5337},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/ps.5337.pdf:pdf},
issn = {1526-498X},
journal = {Pest Management Science},
keywords = {disruptive technology,physical weed control,robotic weeders,robotics,specialty crops},
mendeley-groups = {AI,Robotics,Weed Control},
month = {jul},
number = {7},
pages = {1767--1774},
pmid = {30653830},
publisher = {John Wiley and Sons Ltd},
title = {{Robotic weeders can improve weed control options for specialty crops}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ps.5337},
volume = {75},
year = {2019}
}
@article{westwood2018weed,
abstract = {The discipline of weed science is at a critical juncture. Decades of efficient chemical weed control have led to a rise in the number of herbicide-resistant weed populations, with few new herbicides with unique modes of action to counter this trend and often no economical alternatives to herbicides in large-acreage crops. At the same time, the world population is swelling, necessitating increased food production to feed an anticipated 9 billion people by the year 2050. Here, we consider these challenges along with emerging trends in technology and innovation that offer hope of providing sustainable weed management into the future. The emergence of natural product leads in discovery of new herbicides and biopesticides suggests that new modes of action can be discovered, while genetic engineering provides additional options for manipulating herbicide selectivity and creating entirely novel approaches to weed management. Advances in understanding plant pathogen interactions will contribute to developing new biological control agents, and insights into plant-plant interactions suggest that crops can be improved by manipulating their response to competition. Revolutions in computing power and automation have led to a nascent industry built on using machine vision and global positioning system information to distinguish weeds from crops and deliver precision weed control. These technologies open multiple possibilities for efficient weed management, whether through chemical or mechanical mechanisms. Information is also needed by growers to make good decisions, and will be delivered with unprecedented efficiency and specificity, potentially revolutionizing aspects of extension work. We consider that meeting the weed management needs of agriculture by 2050 and beyond is a challenge that requires commitment by funding agencies, researchers, and students to translate new technologies into durable weed management solutions. Integrating old and new weed management technologies into more diverse weed management systems based on a better understanding of weed biology and ecology can provide integrated weed management and resistance management strategies that will be more sustainable than the technologies that are now failing.},
author = {Westwood, James H. and Charudattan, Raghavan and Duke, Stephen O. and Fennimore, Steven A. and Marrone, Pam and Slaughter, David C. and Swanton, Clarence and Zollinger, Richard},
doi = {10.1017/wsc.2017.78},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Westwood et al. - Unknown - Weed Management in 2050 Perspectives on the Future of Weed Science.pdf:pdf},
issn = {15502759},
journal = {Weed Science},
keywords = {Biological control,biopesticides,competition,information technology,novel herbicides,precision agriculture,robotics,student training},
mendeley-groups = {Weed Control,Precision Agriculture,Review Paper},
number = {3},
pages = {275--285},
publisher = {Cambridge University Press},
title = {{Weed Management in 2050: Perspectives on the Future of Weed Science}},
url = {https://doi.org/10.1017/wsc.2017.78},
volume = {66},
year = {2018}
}
@techreport{Hinton,
abstract = {A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagat-ing through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.},
author = {Hinton, Geoffrey and Sabour, Sara and {Frosst Google Brain Toronto}, Nicholas},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Hinton, Sabour, Frosst Google Brain Toronto - Unknown - MATRIX CAPSULES WITH EM ROUTING.pdf:pdf},
title = {{MATRIX CAPSULES WITH EM ROUTING}}
}
@inproceedings{Huang2018,
abstract = {Precision weed management, an application of precision agriculture, accounts for within-field variability of weed infestation and herbicide damage. Unmanned aerial vehicles (UAVs) provide a unique platform for remote sensing of field crops. They are more efficient and flexible than manned agricultural airplanes in acquiring high-resolution images at low altitudes and low speeds. UAVs are more universal than agricultural aircraft, because the latter are used only in specific regions. We have developed and used UAV systems for red-green-blue digital and color-infrared imaging over crop fields to identify weed species, determine crop injury from dicamba at different doses, and detect naturally grown glyphosate-resistant weeds. This article presents remote sensing technologies for weed management and focuses on development and application of UAV-based low-altitude remote sensing technology for precision weed management. In particular, this article futher discusses the potential application of UAV-based plant-sensing systems for mapping the distributions of glyphosate-resistant and glyphosate-susceptible weeds in crop fields. Nomenclature: Dicamba; glyphosate.},
author = {Huang, Yanbo and Reddy, Krishna N. and Fletcher, Reginald S. and Pennington, Dean},
booktitle = {Weed Technology},
doi = {10.1017/wet.2017.89},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Huang et al. - 2018 - UAV Low-Altitude Remote Sensing for Precision Weed Management.pdf:pdf},
issn = {0890037X},
keywords = {Glyphosate-Resistant weeds,Low-Altitude remote sensing,precision agriculture,unmanned aerial vehicle},
mendeley-groups = {UAV,Image Processing,Precision Agriculture},
month = {jan},
number = {1},
pages = {2--6},
publisher = {Cambridge University Press},
title = {{UAV Low-Altitude Remote Sensing for Precision Weed Management}},
url = {https://doi.org/10.1017/wet.2017.89},
volume = {32},
year = {2018}
}
@article{Radoglou-Grammatikis2020,
abstract = {Climate change has introduced significant challenges that can affect multiple sectors, including the agricultural one. In particular, according to the Food and Agriculture Organization of the United Nations (FAO) and the International Telecommunication Union (ITU), the world population has to find new solutions to increase the food production by 70% by 2050. The answer to this crucial challenge is the suitable adoption and utilisation of the Information and Communications Technology (ICT) services, offering capabilities that can increase the productivity of the agrochemical products, such as pesticides and fertilisers and at the same time, they should minimise the functional cost. More detailed, the advent of the Internet of Things (IoT) and specifically, the rapid evolution of the Unmanned Aerial Vehicles (UAVs) and Wireless Sensor Networks (WSNs) can lead to valuable and at the same time economic Precision Agriculture (PA) applications, such as aerial crop monitoring and smart spraying tasks. In this paper, we provide a survey regarding the potential use of UAVs in PA, focusing on 20 relevant applications. More specifically, first, we provide a detailed overview of PA, by describing its various aspects and technologies, such as soil mapping and production mapping as well as the role of the Global Positioning Systems (GPS) and Geographical Information Systems (GIS). Then, we discriminate and analyse the various types of UAVs based on their technical characteristics and payload. Finally, we investigate in detail 20 UAV applications that are devoted to either aerial crop monitoring processes or spraying tasks. For each application, we examine the methodology adopted, the proposed UAV architecture, the UAV type, as well as the UAV technical characteristics and payload.},
author = {Radoglou-Grammatikis, Panagiotis and Sarigiannidis, Panagiotis and Lagkas, Thomas and Moscholios, Ioannis},
doi = {10.1016/j.comnet.2020.107148},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Radoglou-Grammatikis et al. - 2020 - A compilation of UAV applications for precision agriculture.pdf:pdf},
issn = {13891286},
journal = {Computer Networks},
keywords = {Precision agriculture (PA),Remote sensing (RS),Unmanned aerial vehicle (UAV)},
mendeley-groups = {UAV,Precision Agriculture},
month = {may},
pages = {107148},
publisher = {Elsevier B.V.},
title = {{A compilation of UAV applications for precision agriculture}},
volume = {172},
year = {2020}
}
@inproceedings{Hinton2011,
abstract = {The artificial neural networks that are used to recognise shapes typcially use one or more layers of learned feature detectors that produce scalar outputs. By contrast, the computer vision community uses complicated, hand-engineered representations of the pose of the feature, like SIFT, that produce a whole vector of outputs including an explicit representation of the pose of the feature. We show how neural networks can be used to learn features that output a whole vector of instatiation parameters and we argue that this is a much more promising way of dealing with variations in position, orientation, scale and lighting than the methods currently employed in the neural networks community. It is also more promising than the hand-engineered features currently used in computer vision because it provides an efficient way of adpating the features to the domain},
author = {Hinton, Geoffrey E. and Krizhevsky, Alex and Wang, Sida D.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-21735-7_6},
file = {:C\:/Users/Salazar/Documents/Mendeley Desktop/Hinton, Krizhevsky, Wang - 2011 - LNCS 6791 - Transforming Auto-Encoders.pdf:pdf},
isbn = {9783642217340},
issn = {03029743},
keywords = {Invariance,auto-encoder,shape representation},
number = {PART 1},
pages = {44--51},
title = {{Transforming auto-encoders}},
volume = {6791 LNCS},
year = {2011}
}
